{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ec2-user/sparkstreaming/src/main/python/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, udf, col, size\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "#from utils.text_utils import *\n",
    "from config.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Default list of Stopwords\n",
    "STOPWORDS_CORE = ['a', u'about', u'above', u'after', u'again', u'against', u'all', u'am', u'an', u'and', u'any', u'are', u'arent', u'as', u'at',\n",
    "                  u'be', u'because', u'been', u'before', u'being', u'below', u'between', u'both', u'but', u'by',\n",
    "                  u'can', 'cant', 'come', u'could', 'couldnt',\n",
    "                  u'd', u'did', u'didn', u'do', u'does', u'doesnt', u'doing', u'dont', u'down', u'during',\n",
    "                  u'each',\n",
    "                  u'few', 'finally', u'for', u'from', u'further',\n",
    "                  u'had', u'hadnt', u'has', u'hasnt', u'have', u'havent', u'having', u'he', u'her', u'here', u'hers', u'herself', u'him', u'himself', u'his', u'how',\n",
    "                  u'i', u'if', u'in', u'into', u'is', u'isnt', u'it', u'its', u'itself',\n",
    "                  u'just',\n",
    "                  u'll',\n",
    "                  u'm', u'me', u'might', u'more', u'most', u'must', u'my', u'myself',\n",
    "                  u'no', u'nor', u'not', u'now',\n",
    "                  u'o', u'of', u'off', u'on', u'once', u'only', u'or', u'other', u'our', u'ours', u'ourselves', u'out', u'over', u'own',\n",
    "                  u'r', u're',\n",
    "                  u's', 'said', u'same', u'she', u'should', u'shouldnt', u'so', u'some', u'such',\n",
    "                  u't', u'than', u'that', 'thats', u'the', u'their', u'theirs', u'them', u'themselves', u'then', u'there', u'these', u'they', u'this', u'those', u'through', u'to', u'too',\n",
    "                  u'under', u'until', u'up',\n",
    "                  u'very',\n",
    "                  u'was', u'wasnt', u'we', u'were', u'werent', u'what', u'when', u'where', u'which', u'while', u'who', u'whom', u'why', u'will', u'with', u'wont', u'would',\n",
    "                  u'y', u'you', u'your', u'yours', u'yourself', u'yourselves']\n",
    "\n",
    "# Custom List of Stopwords - Add your own here\n",
    "STOPWORDS_CUST = ['']\n",
    "STOPWORDS = STOPWORDS_CORE + STOPWORDS_CUST\n",
    "\n",
    "def cleanup_text(text, word_len_thres=2):\n",
    "    words = text.split(\" \")\n",
    "    # Remove special characters\n",
    "    text_out = [re.sub('[^a-zA-Z0-9]','',word) for word in words]\n",
    "    # Remove stopwords and words under X length\n",
    "    text_out = [word.lower() for word in text_out if len(word)>word_len_thres and word.lower() not in STOPWORDS]\n",
    "    return text_out\n",
    "\n",
    "def array_to_string(my_list):\n",
    "    return '[' + ','.join([str(elem) for elem in my_list]) + ']'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredToCsv\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame representing the stream of input lines from connection to localhost:9999\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"127.0.0.1\") \\\n",
    "    .option(\"port\", 9997) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "udf_array_to_string = udf(array_to_string, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lines into words\n",
    "words = lines.select(udf_cleantext(lines.value).alias(\"text_preprocessed\")) \\\n",
    "    .filter(size(col(\"text_preprocessed\"))>0) \\\n",
    "    .select(udf_array_to_string(col(\"text_preprocessed\")).alias(\"text_preprocessed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start running the query that prints the running counts to the console\n",
    "query = words \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start running the query that prints the running counts to the console\n",
    "query = words \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"csv\") \\\n",
    "    .option('delimiter', '|') \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint\") \\\n",
    "    .option(\"path\", CSV_STREAMING_OUT_PATH) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
